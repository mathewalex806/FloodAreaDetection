{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load .tif file\n",
    "tif_path = \"/home/alex/Desktop/miniproject/VH.tif\"\n",
    "\n",
    "with rasterio.open(tif_path) as src:\n",
    "    image = src.read(1).astype(np.float32)  # Read the first band\n",
    "\n",
    "# Apply log transformation as per the paper\n",
    "image = 10 * np.log10(image + 1e-6) + 50  \n",
    "\n",
    "image = (image - np.min(image)) / (np.max(image) - np.min(image))  \n",
    "image = (image * 2) - 1  \n",
    "\n",
    "# Display image\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.colorbar(label=\"Normalized Pixel Intensity\")\n",
    "plt.title(\"Normalized SAR Image (Paper Method)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the directories relative to the working directory\n",
    "labels_dir = 'archive/sen12flood/sen12floods_s1_labels/sen12floods_s1_labels'\n",
    "source_dir = 'archive/sen12flood/sen12floods_s1_source/sen12floods_s1_source'\n",
    "\n",
    "# List and sort the label directories for reproducibility\n",
    "label_dirs = sorted([d for d in os.listdir(labels_dir) if os.path.isdir(os.path.join(labels_dir, d))])\n",
    "\n",
    "# Shuffle and select half of the directories to delete\n",
    "random.shuffle(label_dirs)\n",
    "num_to_delete = len(label_dirs) // 2\n",
    "dirs_to_delete = label_dirs[:num_to_delete]\n",
    "\n",
    "deleted_pairs = 0\n",
    "\n",
    "for dirname in dirs_to_delete:\n",
    "    label_path = os.path.join(labels_dir, dirname)\n",
    "    # Replace label prefix with source prefix to form the corresponding source directory name\n",
    "    source_dirname = dirname.replace(\"sen12floods_s1_labels\", \"sen12floods_s1_source\", 1)\n",
    "    source_path = os.path.join(source_dir, source_dirname)\n",
    "    \n",
    "    # Only delete if both the label and source directories exist\n",
    "    if os.path.isdir(label_path) and os.path.isdir(source_path):\n",
    "        shutil.rmtree(label_path)\n",
    "        shutil.rmtree(source_path)\n",
    "        deleted_pairs += 1\n",
    "        print(f\"Deleted pair: {label_path} and {source_path}\")\n",
    "    else:\n",
    "        print(f\"Skipping {dirname}: Pair not found (label exists: {os.path.isdir(label_path)}, source exists: {os.path.isdir(source_path)})\")\n",
    "\n",
    "print(f\"Total deleted pairs: {deleted_pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FloodDataset(Dataset):\n",
    "    def __init__(self, source_dir, labels_dir, target_size=(512, 512), transform=None):\n",
    "        self.source_dir = source_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.target_size = target_size  # Fixed size for all images\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get list of SAR image directories (sorted for consistency)\n",
    "        self.sample_ids = sorted(os.listdir(source_dir))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_ids)\n",
    "    \n",
    "    def preprocess_sar(self, image):\n",
    "        \"\"\"Apply log transformation and normalize to [-1,1].\"\"\"\n",
    "        # Apply log transformation first\n",
    "        image = 10 * np.log10(image + 1e-6) + 50  # Avoid log(0)\n",
    "        \n",
    "        # Compute denominator safely\n",
    "        img_min = np.min(image)\n",
    "        img_max = np.max(image)\n",
    "        denom = img_max - img_min\n",
    "        if denom < 1e-6:\n",
    "            # If the image has no contrast, set it to zeros\n",
    "            image = np.zeros_like(image)\n",
    "        else:\n",
    "            image = (image - img_min) / denom  # Normalize to [0,1]\n",
    "        \n",
    "        # Scale to [-1,1]\n",
    "        image = (image * 2) - 1\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    \n",
    "    def get_flood_label(self, label_path):\n",
    "        \"\"\"Read labels.geojson and return flood label (0 or 1).\"\"\"\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Missing label file {label_path}\")\n",
    "            return 0  # Default to no flood if label is missing\n",
    "        \n",
    "        with open(label_path, \"r\") as f:\n",
    "            label_data = json.load(f)\n",
    "        return 1 if label_data[\"properties\"].get(\"FLOODING\", False) else 0\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_id = self.sample_ids[idx]\n",
    "        sample_dir = os.path.join(self.source_dir, sample_id)\n",
    "        \n",
    "        # Find VH.tif within the sample directory (search recursively)\n",
    "        vh_file = None\n",
    "        for root, dirs, files in os.walk(sample_dir):\n",
    "            if \"VH.tif\" in files:\n",
    "                vh_file = os.path.join(root, \"VH.tif\")\n",
    "                break\n",
    "        if vh_file is None:\n",
    "            raise FileNotFoundError(f\"VH.tif not found in directory: {sample_dir}\")\n",
    "        image_path = vh_file\n",
    "        \n",
    "        # Construct label path by replacing source with labels in the directory name\n",
    "        label_subdir = sample_id.replace(\"sen12floods_s1_source\", \"sen12floods_s1_labels\")\n",
    "        label_path = os.path.join(self.labels_dir, label_subdir, \"labels.geojson\")\n",
    "        \n",
    "        # Check if label file exists\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Missing label for {sample_id}, skipping.\")\n",
    "            return self.__getitem__((idx + 1) % len(self.sample_ids))\n",
    "        \n",
    "        # Load SAR image\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read(1).astype(np.float32)  # Read single-band VH SAR image\n",
    "        image = self.preprocess_sar(image)\n",
    "        \n",
    "        # Convert the numpy array to a torch tensor and add channel dimension: (1, H, W)\n",
    "        image = torch.tensor(image).unsqueeze(0)\n",
    "        # Resize image to target size (batch stacking requires same size)\n",
    "        image = F.interpolate(image.unsqueeze(0), size=self.target_size, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        # Load flood label (global scalar label: 0 or 1)\n",
    "        flood_label = self.get_flood_label(label_path)\n",
    "        label = torch.tensor(flood_label, dtype=torch.float32)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Example usage:\n",
    "# Ensure these directories point to the folders that directly contain your sample subdirectories.\n",
    "dataset = FloodDataset(\n",
    "    source_dir=\"/home/alex/Desktop/miniproject/archive/sen12flood/sen12floods_s1_source/sen12floods_s1_source\", \n",
    "    labels_dir=\"/home/alex/Desktop/miniproject/archive/sen12flood/sen12floods_s1_labels/sen12floods_s1_labels\",\n",
    "    target_size=(512, 512)\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Check a sample:\n",
    "sample_image, sample_label = dataset[0]\n",
    "print(\"Image shape:\", sample_image.shape)  # Expected: (1, 512, 512)\n",
    "print(\"Flood label:\", sample_label)  # 0 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.double_conv(in_channels, 64)\n",
    "        self.enc2 = self.double_conv(64, 128)\n",
    "        self.enc3 = self.double_conv(128, 256)\n",
    "        self.enc4 = self.double_conv(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.double_conv(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = self.upconv(1024, 512)\n",
    "        self.dec4 = self.double_conv(1024, 512)\n",
    "        self.upconv3 = self.upconv(512, 256)\n",
    "        self.dec3 = self.double_conv(512, 256)\n",
    "        self.upconv2 = self.upconv(256, 128)\n",
    "        self.dec2 = self.double_conv(256, 128)\n",
    "        self.upconv1 = self.upconv(128, 64)\n",
    "        self.dec1 = self.double_conv(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.downsample(e1))\n",
    "        e3 = self.enc3(self.downsample(e2))\n",
    "        e4 = self.enc4(self.downsample(e3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.downsample(e4))\n",
    "        \n",
    "        # Decoder\n",
    "        d4 = self.upconv4(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        # Output\n",
    "        return torch.sigmoid(self.final_conv(d1))\n",
    "    \n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def downsample(self, x):\n",
    "        return F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "    \n",
    "    def upconv(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "# Example: Initialize the model\n",
    "model = UNet(in_channels=1, out_channels=1)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration: use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the UNet model and move it to the device\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Update DataLoader settings to reduce memory usage\n",
    "# Using a smaller batch size and num_workers=0 ensures minimal memory load.\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "num_epochs = 20\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images = images.to(device)\n",
    "        # Adjust labels shape to (batch, 1)\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: model outputs shape (batch, 1, H, W)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Global average pooling to get a single prediction per image\n",
    "        outputs = torch.mean(outputs, dim=(2,3))  # Now shape: (batch, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    remaining_epochs = num_epochs - epoch - 1\n",
    "    estimated_remaining_time = remaining_epochs * epoch_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Epoch Time: {epoch_time:.2f} sec, \"\n",
    "          f\"Estimated Remaining Time: {estimated_remaining_time:.2f} sec\")\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"Training complete in {total_time/60:.2f} minutes.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"unet_flood_model.pth\")\n",
    "print(\"Model saved as unet_flood_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes, closing, disk\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "model.load_state_dict(torch.load(\"unet_flood_model.pth\", map_location=device))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# 2) IMAGE LOADING\n",
    "# -----------------------------------------------------------------------------------\n",
    "def load_sar_image(image_path, target_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Load SAR image from file, preprocess it, and resize it to a compatible size.\n",
    "    \"\"\"\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read(1).astype(np.float32)\n",
    "    \n",
    "    # Apply log transformation and normalize to [-1,1]\n",
    "    image = 10 * np.log10(image + 1e-6) + 50\n",
    "    image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    image = (image * 2) - 1\n",
    "    \n",
    "    \n",
    "    image = torch.tensor(image).unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, H, W)\n",
    "\n",
    "    \n",
    "    image = F.interpolate(image, size=target_size, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    return image\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# 3) IMPROVED OTSU MASK CREATION\n",
    "# -----------------------------------------------------------------------------------\n",
    "def create_ground_truth_from_sar(sar_image_tensor):\n",
    "    \"\"\"\n",
    "    Create a synthetic water mask from the SAR image using Otsu's threshold.\n",
    "    Then apply morphological operations to reduce noise and improve continuity.\n",
    "    \"\"\"\n",
    "    # Remove batch and channel dimensions and convert to numpy\n",
    "    sar_image = sar_image_tensor.cpu().squeeze().numpy()\n",
    "    \n",
    "    # Compute threshold using Otsu's method\n",
    "    otsu_thresh = threshold_otsu(sar_image)\n",
    "    print(\"Otsu threshold:\", otsu_thresh)\n",
    "    \n",
    "    # Create binary mask: water is assumed to have values below the threshold\n",
    "    water_mask = (sar_image < otsu_thresh).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    selem = disk(3)  \n",
    "    water_mask = closing(water_mask, selem)\n",
    "    water_mask = remove_small_objects(water_mask.astype(bool), min_size=64)\n",
    "    water_mask = remove_small_holes(water_mask, area_threshold=64)\n",
    "    \n",
    "    # Convert boolean mask back to uint8 (0 or 1)\n",
    "    water_mask = water_mask.astype(np.uint8)\n",
    "    \n",
    "    return water_mask\n",
    "\n",
    "\n",
    "image_path = \"VH.tif\"\n",
    "test_image = load_sar_image(image_path, target_size=(512, 512))  # Ensure correct input size\n",
    "\n",
    "\n",
    "synthetic_gt = create_ground_truth_from_sar(test_image)\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# 5) MODEL INFERENCE\n",
    "# -----------------------------------------------------------------------------------\n",
    "with torch.no_grad():\n",
    "    pred_mask = model(test_image)\n",
    "\n",
    "# Convert prediction to numpy\n",
    "pred_mask_np = pred_mask.cpu().squeeze().numpy()\n",
    "\n",
    "# Threshold the model's output to create a binary flood mask\n",
    "threshold_value = 0.5  \n",
    "binary_mask = (pred_mask_np > threshold_value).astype(int)\n",
    "\n",
    "\n",
    "binary_mask = 1 - binary_mask\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# 6) EVALUATION (Flood Score & Accuracy)\n",
    "# -----------------------------------------------------------------------------------\n",
    "# Flood Score: percentage of non-flooded pixels (value=1) in the inverted mask\n",
    "non_flooded_fraction = (binary_mask.sum() / binary_mask.size) * 100\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# 7) VISUALIZATION\n",
    "# -----------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(24,6))\n",
    "\n",
    "# Original SAR Image\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(test_image.cpu().squeeze(), cmap=\"gray\")\n",
    "plt.title(\"SAR Image\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Predicted Flood Probability\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(pred_mask_np, cmap=\"jet\")\n",
    "plt.title(\"Predicted Flood Probability\")\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
